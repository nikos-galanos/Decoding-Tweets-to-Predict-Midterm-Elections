{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "CE73sJkMh4NX",
    "outputId": "09c76521-2bd6-41ce-91bb-7fe3d92f431f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/nikosgalanos/opt/anaconda3/lib/python3.9/site-packages (4.10.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /Users/nikosgalanos/opt/anaconda3/lib/python3.9/site-packages (from tweepy) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /Users/nikosgalanos/opt/anaconda3/lib/python3.9/site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /Users/nikosgalanos/opt/anaconda3/lib/python3.9/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nikosgalanos/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nikosgalanos/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/nikosgalanos/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nikosgalanos/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bNHMCqf5mz1R"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import tweepy\n",
    "import ssl\n",
    "import pandas as pd\n",
    "import io\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWWSYbhkMCzh"
   },
   "source": [
    "## Create Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "urFOCMwHX-uS"
   },
   "outputs": [],
   "source": [
    "token = 'insert your token'\n",
    "client = tweepy.Client(bearer_token=token, wait_on_rate_limit=True)\n",
    "apikey = \"insert your apikey\"\n",
    "apisecretkey = \"insert your api secret key\"\n",
    "accesstoken = \"insert your access token\"\n",
    "accesstokensecret = \"insert your secret access token\"\n",
    "auth = tweepy.OAuthHandler(apikey,apisecretkey) \n",
    "auth.set_access_token(accesstoken,accesstokensecret) \n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bPDY4TdRnzih"
   },
   "outputs": [],
   "source": [
    "# Save senators usernames here --> due to api limitations we cannot download the twees of all senators together\n",
    "# Experience showed that 2-3 senators at a time work\n",
    "usernames = [\"BillRedpath\", \"ConnorVlakancic\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xH1swEKkMOJd"
   },
   "source": [
    "Pull data\n",
    ".items(n) returns n tweets => 100 items result in 1 request.\n",
    "\n",
    "For api.search_30_day we have a limit of 250 requests and a tweet cap of 25k tweets - This is a PREMIUM SEARCH API that allows us to query beyond 7 days.\n",
    "\n",
    "There is an api.search_full_archive that allows us to query till 15 years back but it has even tighter limits.\n",
    "\n",
    "If you want to pull replies by tweets - MAKE SURE YOU'RE NOT EXHAUSTING YOUR LIMITS - One alternative is to try APIv2 search endpoint but it only returns tweets and replies upto last 7 days.\n",
    "\n",
    "Note: you cannot access Premium APIs without elevated access.\n",
    "\n",
    "Read more on Twitter APIs and Tweepy Documentation.\n",
    "\n",
    "https://developer.twitter.com/en/docs/twitter-api/premium\n",
    "\n",
    "https://developer.twitter.com/en/docs/twitter-api/v1\n",
    "\n",
    "\n",
    "\n",
    "https://docs.tweepy.org/en/stable/api.html - For Twitter API v1\n",
    "\n",
    "https://docs.tweepy.org/en/stable/client.html - For Twitter API v2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Twitter connection and get relevant data (users, tweets, replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDljwBYhn4-w"
   },
   "outputs": [],
   "source": [
    "userList = []\n",
    "tweetList = []\n",
    "replyList = []\n",
    "for username in usernames:\n",
    "  # get user profile from username\n",
    "  user = client.get_user(username=username, user_fields=['public_metrics', 'created_at', 'description', 'location', 'verified'])\n",
    "  userList.append({\n",
    "      \"name\":user[0][\"name\"],\n",
    "      \"username\":username,\n",
    "      \"id\":user[0][\"id\"],\n",
    "      \"public_metrics\": user[0][\"public_metrics\"],\n",
    "      \"description\": user[0][\"description\"],\n",
    "      \"location\": user[0][\"location\"],\n",
    "      \"verified\": user[0][\"verified\"]\n",
    "  })\n",
    "  tweetIDs = set()\n",
    "\n",
    "  # get tweets by user\n",
    "  time.sleep(0.01)\n",
    "  tweets = tweepy.Cursor(api.search_30_day, label=\"dev\", query = f\"from:{username} lang:en\", fromDate=\"202201010000\").items(200)\n",
    "  for tweet in tweets:    \n",
    "    tweet = tweet._json\n",
    "    hashtags = [tweet[\"entities\"][\"hashtags\"][i][\"text\"] for i in range(len(tweet[\"entities\"][\"hashtags\"]))] \n",
    "    if \"extended_tweet\" in tweet:\n",
    "      tweet[\"text\"] = tweet[\"extended_tweet\"][\"full_text\"]\n",
    "      hashtags = [tweet[\"extended_tweet\"][\"entities\"][\"hashtags\"][i][\"text\"] for i in range(len(tweet[\"extended_tweet\"][\"entities\"][\"hashtags\"]))] \n",
    "    tweetList.append({\n",
    "        \"tweetId\": tweet[\"id\"],\n",
    "        \"text\": tweet[\"text\"],\n",
    "        \"username\": username,\n",
    "        \"quotes\":tweet[\"quote_count\"],\n",
    "        \"favorites\": tweet[\"favorite_count\"],\n",
    "        \"replies\": tweet['reply_count'],\n",
    "        \"retweets\": tweet[\"retweet_count\"],\n",
    "        \"created_at\": tweet[\"created_at\"],\n",
    "        \"hashtags\":  hashtags      \n",
    "\n",
    "    })\n",
    "    tweetIDs.add(tweet[\"id\"])\n",
    "\n",
    "  # get latest replies for a user - cannot filter on conversation ID because each tweet ID will result in a single request and we are allowed only 250 requests \n",
    "  replies = tweepy.Cursor(api.search_30_day, label=\"dev\", query = f\"to:{username} lang:en\", fromDate=\"202209150000\").items(1000)\n",
    "  for reply in replies:\n",
    "    reply = reply._json\n",
    "    reply_to = reply[\"in_reply_to_status_id\"]\n",
    "    if reply_to not in tweetIDs:\n",
    "      continue\n",
    "    hashtags = [reply[\"entities\"][\"hashtags\"][i][\"text\"] for i in range(len(reply[\"entities\"][\"hashtags\"]))]\n",
    "    if \"extended_tweet\" in reply:\n",
    "      reply[\"text\"] = reply[\"extended_tweet\"][\"full_text\"]\n",
    "      hashtags = [reply[\"extended_tweet\"][\"entities\"][\"hashtags\"][i][\"text\"] for i in range(len(reply[\"extended_tweet\"][\"entities\"][\"hashtags\"]))]\n",
    "    replyList.append({\n",
    "        \"tweetId\": reply[\"id\"],\n",
    "        \"replyTo\": reply_to,\n",
    "        \"text\": reply[\"text\"],\n",
    "        \"created_at\": reply[\"created_at\"],\n",
    "        \"quotes\":reply[\"quote_count\"],\n",
    "        \"favorites\": reply[\"favorite_count\"],\n",
    "        \"replies\": reply['reply_count'],\n",
    "        \"retweets\": reply[\"retweet_count\"],\n",
    "        \"hashtags\": hashtags,\n",
    "        \"userId\": reply[\"user\"][\"id\"],\n",
    "        \"username\":reply[\"user\"][\"screen_name\"],\n",
    "        \"name\": reply[\"user\"][\"name\"],\n",
    "        \"followers\":reply[\"user\"][\"followers_count\"],\n",
    "        \"following\":reply[\"user\"][\"friends_count\"],\n",
    "        \"verified\":reply[\"user\"][\"verified\"]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZybUzfDV4Kpy"
   },
   "outputs": [],
   "source": [
    "## Create dataframes of the downloaded data and export them to excel files\n",
    "\n",
    "df1 = pd.DataFrame(userList)\n",
    "df2 = pd.DataFrame(tweetList)\n",
    "df3 = pd.DataFrame(replyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zm0t4Jm1_h7"
   },
   "outputs": [],
   "source": [
    "df1.to_excel(\"users.xlsx\", index=False)\n",
    "df2.to_excel(\"tweets.xlsx\", index=False)\n",
    "df3.to_excel(\"reply.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "jRs38xKZ0lUY",
    "outputId": "7eabcff8-488b-4ccd-bede-3ba2e5383480"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_65240f62-5dd6-4a47-82ba-7446363e9abd\", \"tweets.xlsx\", 23969)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_650c976d-bf6a-4f06-9e35-e6bb35c91e8a\", \"reply.xlsx\", 131404)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(\"users.xlsx\")\n",
    "files.download(\"tweets.xlsx\")\n",
    "files.download(\"reply.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
